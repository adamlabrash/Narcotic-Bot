2021-08-10 13:39:32 [twisted] CRITICAL: Unhandled error in Deferred:
2021-08-10 13:39:32 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/selenium/webdriver/common/service.py", line 72, in start
    self.process = subprocess.Popen(cmd, env=self.env,
  File "/usr/lib/python3.8/subprocess.py", line 858, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/lib/python3.8/subprocess.py", line 1704, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'geckodriver'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/adam/darknet-analysis/src/darknet/spiders/whiteHouseMarket.py", line 42, in __init__
    self.driver = TorBrowserDriver(tbb_path="/home/adam/Desktop/tor-browser_en-US/")
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/tbselenium/tbdriver.py", line 60, in __init__
    super(TorBrowserDriver, self).__init__(
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/selenium/webdriver/firefox/webdriver.py", line 164, in __init__
    self.service.start()
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/selenium/webdriver/common/service.py", line 81, in start
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'geckodriver' executable needs to be in PATH. 


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/crawler.py", line 86, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/crawler.py", line 98, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/spiders/__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/adam/darknet-analysis/src/darknet/spiders/whiteHouseMarket.py", line 46, in __init__
    print('Error starting tor browser, make sure the path is correct in your .env file')
  File "/home/adam/darknet-analysis/src/darknet/spiders/whiteHouseMarket.py", line 46, in __init__
    print('Error starting tor browser, make sure the path is correct in your .env file')
  File "/usr/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
2021-08-10 13:39:59 [twisted] CRITICAL: Unhandled error in Deferred:
2021-08-10 13:39:59 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/core/downloader/__init__.py", line 83, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'random_useragent'
2021-08-10 13:51:05 [twisted] CRITICAL: Unhandled error in Deferred:
2021-08-10 13:51:05 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/twisted/internet/defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/core/downloader/__init__.py", line 83, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/adam/darknet-analysis/venv/lib/python3.8/site-packages/scrapy/utils/misc.py", line 61, in load_object
    mod = import_module(module)
  File "/usr/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/adam/darknet-analysis/src/darknet/middlewares.py", line 15, in <module>
    import requests
ModuleNotFoundError: No module named 'requests'
